{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f26ddd3",
   "metadata": {},
   "source": [
    "\n",
    "# Lab 9: Build a Log Aggregator\n",
    "\n",
    "In this lab, you will create your own log generator, build a command-line utility that scans log files, summarizes their contents, and provides insight into system behavior. Data structures to track log message levels such as `INFO`, `WARNING`, `ERROR`, and `CRITICAL`.\n",
    "\n",
    "This lab reinforces:\n",
    "- File I/O\n",
    "- Pattern recognition (regex)\n",
    "- Dictionaries and counters\n",
    "- Functions and modularity\n",
    "- CLI arguments, logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d5ee8a",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: Create Log files (20%)\n",
    "Using the the following example log format below create a **python file** that will log errors In a structured tree format \n",
    "\n",
    "You will find examples in the folder called Logs that you can use to build your program.\n",
    "\n",
    "Remember set of logs should have a varied levels of log entries (`INFO`, `WARNING`, `ERROR`, `CRITICAL`) and tailored message types for different service components.\n",
    "You must create 5 structured logs here are some examples:\n",
    "\n",
    "    sqldb\n",
    "    ui\n",
    "    frontend.js\n",
    "    backend.js\n",
    "    frontend.flask\n",
    "    backend.flask\n",
    "\n",
    "You may use chat GPT to create sample outputs NOT THE LOGS. IE:\n",
    "\n",
    "    System failure\n",
    "    Database corruption\n",
    "    Disk failure detected\n",
    "    Database corruption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9ba30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging: Trying to access file at path: 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\my_app_utils_db.log'\n",
      "Error: Log file 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\my_app_utils_db.log' not found.\n",
      "Debugging: Trying to access file at path: 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\my_app_utils.log'\n",
      "Error: Log file 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\my_app_utils.log' not found.\n",
      "Debugging: Trying to access file at path: 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\my_app.log'\n",
      "Error: Log file 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\my_app.log' not found.\n",
      "Debugging: Trying to access file at path: 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\RSVP_Agent_processing.log'\n",
      "Error: Log file 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\RSVP_Agent_processing.log' not found.\n",
      "Debugging: Trying to access file at path: 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\systemd_core_performance.log'\n",
      "Error: Log file 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\systemd_core_performance.log' not found.\n",
      "Debugging: Trying to access file at path: 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\systemd_core.log'\n",
      "Error: Log file 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\systemd_core.log' not found.\n",
      "Debugging: Trying to access file at path: 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\systemd.log'\n",
      "Error: Log file 'C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\systemd.log' not found.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "def log_level_count(log_file):\n",
    "\n",
    "    \"\"\"Counts occurences\"\"\"\n",
    "\n",
    "    level_count = {}\n",
    "\n",
    "    try:\n",
    "        with open(log_file, 'r') as opened_file:\n",
    "\n",
    "            for line in opened_file:\n",
    "                top_line = line.upper()\n",
    "                \n",
    "                if \"INFO:\" in top_line:\n",
    "                    if \"INFO\" not in level_count:\n",
    "                        level_count[\"INFO\"] = 0\n",
    "                    level_count[\"INFO\"] += 1\n",
    "\n",
    "                elif \"WARNING:\" in top_line:\n",
    "                    if \"WARNING\" not in level_count:\n",
    "                        level_count[\"WARNING\"] = 0\n",
    "                    level_count[\"WARNING\", 0] += 1\n",
    "\n",
    "                elif \"ERROR:\" in top_line:\n",
    "                    if \"ERROR\" not in level_count:\n",
    "                        level_count[\"ERROR\"] = 0\n",
    "                    level_count[\"ERROR\", 0] += 1\n",
    "\n",
    "                elif \"CRITICAL:\" in top_line:\n",
    "                    if \"CRITICAL\" not in level_count:\n",
    "                        level_count[\"CRITICAL\"] = 0\n",
    "                    level_count[\"CRITICAL\", 0] += 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {log_file}\")\n",
    "        return {}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred when trying to the read the log files: {e}\")\n",
    "        return {}\n",
    "    \n",
    "    return level_count\n",
    "\n",
    "def extract_messages(log_file):\n",
    "\n",
    "    \"\"\"Extracts messages\"\"\"\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    try:\n",
    "        with open(log_file, 'r') as opened_file:\n",
    "            for each_line in opened_file:\n",
    "\n",
    "                log_levels = [\"INFO:\", \"WARNING:\", \"ERROR:\", \"CRITICAL:\"]\n",
    "\n",
    "                if \"INFO:\" in each_line or \"WARNING:\" in each_line or \"ERROR:\" in each_line or \"CRITICAL:\" in each_line:\n",
    "                    \n",
    "                    colon_position = each_line.find(\":\")\n",
    "\n",
    "                    if colon_position != -1:\n",
    "                        message = each_line[colon_position + 1:].strip()\n",
    "                        messages.append(message)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {log_file}\")\n",
    "        return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred when trying to the read the log files: {e}\")\n",
    "        return []\n",
    "    \n",
    "    return messages\n",
    "\n",
    "def summarize_logs(log_file):\n",
    "\n",
    "    \"\"\"Got help for the messages output format\"\"\"\n",
    "\n",
    "    levels = log_level_count(log_file)\n",
    "    messages = extract_messages(log_file)\n",
    "\n",
    "    if not levels and not messages:\n",
    "        print(\"No log data found or error reading file.\")\n",
    "        return\n",
    "\n",
    "    print(\"Log Summary:\")\n",
    "    print(\"-------------\")\n",
    "    if levels:\n",
    "        print(\"Log Level Counts:\")\n",
    "        for level_name, count_value in levels.items():\n",
    "            print(f\"{level_name}: {count_value}\")\n",
    "    else:\n",
    "        print(\"No log levels found.\")\n",
    "\n",
    "    if messages:\n",
    "        print(\"Sample Log Messages:\")\n",
    "        print(\"---------------\")\n",
    "\n",
    "        for message_index, the_message in enumerate(messages[:5]):\n",
    "            print(f\"  [{message_index+1}] {the_message}\")\n",
    "\n",
    "        if len(messages) > 5:\n",
    "            print(\"  ...\")\n",
    "        print(f\"Total Messages: {len(messages)}\")\n",
    "\n",
    "    else:\n",
    "        print(\"No log messages found.\")\n",
    "\n",
    "def main():\n",
    "\n",
    "    script_directory = os.getcwd()\n",
    "    log_directory = os.path.join(script_directory, \"Logs\")\n",
    "\n",
    "    if not os.path.exists(log_directory) or not os.path.isdir(log_directory):\n",
    "        print(f\"Error: Directory '{log_directory}' not found.\")\n",
    "        return\n",
    "\n",
    "    log_files_to_analyze = [\n",
    "        r\"C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\my_app_utils_db.log\",\n",
    "        r\"C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\my_app_utils.log\",\n",
    "        r\"C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\my_app.log\",\n",
    "        r\"C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\RSVP_Agent_processing.log\",\n",
    "        r\"C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\systemd_core_performance.log\",\n",
    "        r\"C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\systemd_core.log\",\n",
    "        r\"C:\\Users\\Shanto\\Documents\\GitHub\\homeworkfolder-shant-bekverdyan\\Labs\\Lab9\\Logs\\systemd.log\",\n",
    "    ]\n",
    "\n",
    "    for log_file_name in log_files_to_analyze:\n",
    "\n",
    "        log_file_path = os.path.join(log_directory, log_file_name)\n",
    "        print(f\"Debugging: Trying to access file at path: '{log_file_path}'\")\n",
    "\n",
    "        if os.path.exists(log_file_path):\n",
    "            summarize_logs(log_file_path)\n",
    "\n",
    "        else:\n",
    "            print(f\"Error: Log file '{log_file_path}' not found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5255ab",
   "metadata": {},
   "source": [
    "\n",
    "### Example Log Format\n",
    "\n",
    "You will work with logs that follow this simplified structure:\n",
    "\n",
    "```\n",
    "2025-04-11 23:20:36,913 | my_app | INFO | Request completed\n",
    "2025-04-11 23:20:36,914 | my_app.utils | ERROR | Unhandled exception\n",
    "2025-04-11 23:20:36,914 | my_app.utils.db | CRITICAL | Disk failure detected\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3659dfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file '--f=c:\\Users\\Shanto\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3cd7d6d5abe9afbcb8b375ced9527e9bdeb0b1ad4.json' does not exist.\n"
     ]
    }
   ],
   "source": [
    "def summarize_logs(log_file):\n",
    "\n",
    "    \"\"\"Got help for the messages output format\"\"\"\n",
    "\n",
    "    levels = log_level_count(log_file)\n",
    "    messages = extract_messages(log_file)\n",
    "\n",
    "    if not levels and not messages:\n",
    "        print(\"No log data found or error reading file.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nLog Summary:\")\n",
    "    print(\"-------------\")\n",
    "    if levels:\n",
    "        print(\"\\nLog Level Counts:\")\n",
    "        for level_name, count_value in levels.items():\n",
    "            print(f\"{level_name}: {count_value}\")\n",
    "    else:\n",
    "        print(\"\\nNo log levels found.\")\n",
    "\n",
    "    if messages:\n",
    "        print(\"\\nSample Log Messages:\")\n",
    "        print(\"---------------\")\n",
    "\n",
    "        for message_index, the_message in enumerate(messages[:5]):\n",
    "            print(f\"  [{message_index+1}] {the_message}\")\n",
    "\n",
    "        if len(messages) > 5:\n",
    "            print(\"  ...\")\n",
    "        print(f\"\\nTotal Messages: {len(messages)}\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo log messages found.\")\n",
    "\n",
    "def main():\n",
    "\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: python log_analyzer.py <log_file>\")\n",
    "        return\n",
    "\n",
    "    log_file_name = sys.argv[1]\n",
    "\n",
    "    if not os.path.exists(log_file_name):\n",
    "        print(f\"Error: The file '{log_file_name}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    summarize_logs(log_file_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f6e84",
   "metadata": {},
   "source": [
    "## Part 2: Logging the Log File (40%)\n",
    "    New File\n",
    "### Part 2a: Read the Log File (see lab 7) (10%)\n",
    "\n",
    "\n",
    "Write a function to read the contents of a log file into a list of lines. Handle file errors gracefully.\n",
    "\n",
    "### Part 2b: Parse Log Lines (see code below if you get stuck) (10%)\n",
    "\n",
    "Use a regular expression to extract:\n",
    "- Timestamp\n",
    "- Log name\n",
    "- Log level\n",
    "- Message\n",
    "\n",
    "### Part 2c: Count Log Levels (20%)\n",
    "\n",
    "Create a function to count how many times each log level appears. Store the results in a dictionary. Then output it as a Json File\n",
    "You may pick your own format but here is an example. \n",
    "```python\n",
    "{\n",
    "    \"INFO\": \n",
    "    {\n",
    "        \"Request completed\": 42, \n",
    "        \"Heartbeat OK\": 7\n",
    "    }\n",
    "\n",
    "    \"WARNING\":\n",
    "    {\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bc631f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file '--f=c:\\Users\\Shanto\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3cd7d6d5abe9afbcb8b375ced9527e9bdeb0b1ad4.json' does not exist.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "def process_log(log_file_path, output_file=\"log_counts.json\"):\n",
    "\n",
    "    level_counts = {}\n",
    "\n",
    "    try:\n",
    "        with open(log_file_path, 'r') as f:\n",
    "\n",
    "            for line in f:\n",
    "                parts = line.split(\" | \")\n",
    "\n",
    "                if len(parts) >= 4:\n",
    "                    log_level = parts[2].strip().upper()\n",
    "                    message = parts[3].strip()\n",
    "\n",
    "                    if log_level in [\"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\", \"DEBUG\"]:\n",
    "                        if log_level not in level_counts:\n",
    "                            level_counts[log_level] = {}\n",
    "\n",
    "                        if message not in level_counts[log_level]:\n",
    "                            level_counts[log_level][message] = 0\n",
    "\n",
    "                        level_counts[log_level][message] += 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Log file not found at '{log_file_path}'\")\n",
    "        return\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading log file '{log_file_path}': {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(output_file, 'w') as outfile:\n",
    "            json.dump(level_counts, outfile, indent=4)\n",
    "        print(f\"Log level counts have been written to '{output_file}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to JSON file '{output_file}': {e}\")\n",
    "\n",
    "def count_log_levels(log_file):\n",
    "\n",
    "    level_counts = {}\n",
    "\n",
    "    try:\n",
    "        with open(log_file, 'r') as opened_file:\n",
    "\n",
    "            for line in opened_file:\n",
    "                parts = line.split(\" | \")\n",
    "\n",
    "                if len(parts) >= 4:\n",
    "                    log_level = parts[2].strip().upper()\n",
    "\n",
    "                    if log_level in [\"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\", \"DEBUG\"]:\n",
    "\n",
    "                        if log_level not in level_counts:\n",
    "                            level_counts[log_level] = 0\n",
    "                        level_counts[log_level] += 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found - {log_file}\")\n",
    "        return {}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the log file: {e}\")\n",
    "        return {}\n",
    "    \n",
    "    return level_counts\n",
    "\n",
    "def extract_messages(log_file):\n",
    "\n",
    "    the_messages = []\n",
    "\n",
    "    try:\n",
    "        with open(log_file, 'r') as opened_file:\n",
    "\n",
    "            for each_line in opened_file:\n",
    "                parts = each_line.split(\" | \")\n",
    "\n",
    "                if len(parts) >= 4:\n",
    "                    the_message = parts[3].strip()\n",
    "                    the_messages.append(the_message)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found --> {log_file}\")\n",
    "        return []\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "    \n",
    "    return the_messages\n",
    "\n",
    "def summarize_logs(log_file):\n",
    "\n",
    "    print(f\"Analyzing log file: {log_file}\")\n",
    "\n",
    "    levels = count_log_levels(log_file)\n",
    "    messages = extract_messages(log_file)\n",
    "\n",
    "    if not levels and not messages:\n",
    "        print(\"No log data found or error reading file.\")\n",
    "        return\n",
    "\n",
    "    print(\"Log Summary:\")\n",
    "    print(\"-------------\")\n",
    "\n",
    "    if levels:\n",
    "        print(\"Log Level Counts:\")\n",
    "        for level_name, count_value in levels.items():\n",
    "            print(f\"{level_name}: {count_value}\")\n",
    "\n",
    "    else:\n",
    "        print(\"No log levels found.\")\n",
    "\n",
    "    if messages:\n",
    "\n",
    "        print(\"Sample Log Messages:\")\n",
    "\n",
    "        for message_index, the_message in enumerate(messages[:5]):\n",
    "            print(f\"  [{message_index+1}] {the_message}\")\n",
    "\n",
    "        if len(messages) > 5:\n",
    "            print(\"  ...\")\n",
    "        print(f\"Total Messages: {len(messages)}\")\n",
    "\n",
    "    else:\n",
    "        print(\"No log messages found.\")\n",
    "\n",
    "def main():\n",
    "\n",
    "    \"\"\"Got help for this part\"\"\"\n",
    "\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: python log_analyzer.py <log_file>\")\n",
    "        return\n",
    "\n",
    "    log_file_name = sys.argv[1]\n",
    "\n",
    "    if not os.path.exists(log_file_name):\n",
    "        print(f\"Error: The file '{log_file_name}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    process_log(log_file_name)\n",
    "    summarize_logs(log_file_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045c30f",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Generate Summary Report (40%)\n",
    "    New File\n",
    "### Step 3a (20%):\n",
    " Develop a function that continuously monitors your JSON file(s) and will print a real-time summary of log activity. It should keep count of the messages grouped by log level (INFO, WARNING, ERROR, CRITICAL) and display only the critical messages. (I.e. If new data comes in the summary will change and a new critical message will be printed)\n",
    " - note: do not reprocess the entire file on each update.  \n",
    "\n",
    "### Step 3a: Use a Matplotlib (Lecture 10) (20%)\n",
    "Develop a function that continuously monitors your JSON file(s) and will graph in real-time a bar or pie plot of each of the errors.  (a graph for each log level). \n",
    "- The graph should show the distribution of log messages by level  (INFO, WARNING, ERROR, CRITICAL)  \n",
    "\n",
    "\n",
    "### Critical notes:\n",
    "- Your code mus use Daemon Threads (Lecture 14)\n",
    "- 3a and 3b do not need to run at the same time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Log Activity Monitor...\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n",
      "Error: JSON file not found at log_counts.json.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import threading\n",
    "\n",
    "json_file_path = \"log_counts.json\"\n",
    "\n",
    "def monitor_log_activity():\n",
    "    previous_data = {}\n",
    "    critical_messages = []\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            with open(json_file_path, 'r') as log_file:\n",
    "\n",
    "                try:\n",
    "                    current_data = json.load(log_file)\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Error: Invalid JSON format in log file. Waiting for valid data...\")\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "\n",
    "            if current_data != previous_data:\n",
    "                print(\"Log Activity Update:\")\n",
    "                print(\"-\" * 20)\n",
    "\n",
    "                total_messages = 0\n",
    "\n",
    "                for level, messages in current_data.items():\n",
    "\n",
    "                    count = sum(messages.values())\n",
    "                    print(f\"{level}: {count} messages\")\n",
    "                    total_messages += count\n",
    "\n",
    "                print(f\"Total Messages: {total_messages}\")\n",
    "\n",
    "                new_critical_messages = []\n",
    "\n",
    "                if \"CRITICAL\" in current_data:\n",
    "\n",
    "                    current_critical_messages = list(current_data[\"CRITICAL\"].keys())\n",
    "\n",
    "                    new_critical_messages = [\n",
    "                        msg for msg in current_critical_messages if msg not in critical_messages\n",
    "                    ]\n",
    "\n",
    "                    critical_messages.extend(new_critical_messages)\n",
    "\n",
    "                    if new_critical_messages:\n",
    "\n",
    "                        print(\"New Critical Messages:\")\n",
    "                        for msg in new_critical_messages:\n",
    "                            print(f\"  - {msg}\")\n",
    "\n",
    "                previous_data = current_data\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: JSON file not found at {json_file_path}.\")\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error monitoring log activity: {e}\")\n",
    "            time.sleep(1)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    print(\"Starting Log Activity Monitor...\")\n",
    "    activity_thread = threading.Thread(target=monitor_log_activity, daemon=True)\n",
    "    activity_thread.start()\n",
    "\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26eb058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a sample regex that parses a log file and extracts relevant information. \n",
    "# you will need to modify it. Review Lecture 11\n",
    "import re\n",
    "\n",
    "def parse_log_line(line):\n",
    "    pattern = r\"^(.*?)\\s\\|\\s(\\w+)\\s\\|\\s(\\w+)\\s\\|\\s(.*)$\"\n",
    "    match = re.match(pattern, line)\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
